{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cddc13e6",
   "metadata": {},
   "source": [
    "# Earthquake Dataset Analysis (Fixed Version)\n",
    "This notebook performs Exploratory Data Analysis (EDA), Data Transformation with datetime features, and Feature Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c49abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "file_path = \"earthquake-dataset.csv\"  # Ensure the file is in the same folder as the notebook\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00506a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic Info\n",
    "df.info()\n",
    "\n",
    "# Summary statistics\n",
    "df.describe(include=\"all\").T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15937250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Missing values heatmap\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Percentage of missing values\n",
    "df.isnull().mean()*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Datetime Feature Engineering ---\n",
    "# Convert Date + Time to datetime\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], errors=\"coerce\")\n",
    "\n",
    "# Extract useful time features\n",
    "df[\"Year\"] = df[\"Datetime\"].dt.year\n",
    "df[\"Month\"] = df[\"Datetime\"].dt.month\n",
    "df[\"Day\"] = df[\"Datetime\"].dt.day\n",
    "df[\"Hour\"] = df[\"Datetime\"].dt.hour\n",
    "\n",
    "# Drop original Date, Time, and Datetime columns + ID-like columns\n",
    "df = df.drop(columns=[\"Date\", \"Time\", \"Datetime\", \"ID\", \"Source\", \"Location Source\", \"Magnitude Source\"])\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "# Impute missing numeric values with median\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[df.select_dtypes(include=np.number).columns] = imputer.fit_transform(df.select_dtypes(include=np.number))\n",
    "\n",
    "# Scale numeric values\n",
    "scaler = StandardScaler()\n",
    "df[df.select_dtypes(include=np.number).columns] = scaler.fit_transform(df.select_dtypes(include=np.number))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Feature Selection ---\n",
    "# Define target (Magnitude) and features\n",
    "X = df.drop(columns=[\"Magnitude\"])  \n",
    "y = df[\"Magnitude\"]\n",
    "\n",
    "# Discretize magnitude into classes\n",
    "y_class = pd.cut(y, bins=[-np.inf, 4.0, 6.0, np.inf], labels=[\"Low\", \"Medium\", \"High\"])\n",
    "\n",
    "# Random Forest for Feature Importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y_class)\n",
    "\n",
    "# Feature importance plot\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=importances.sort_values(ascending=False), y=importances.sort_values(ascending=False).index)\n",
    "plt.title(\"Feature Importance from Random Forest\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}